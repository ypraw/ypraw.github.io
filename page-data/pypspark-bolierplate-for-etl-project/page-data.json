{
    "componentChunkName": "component---src-templates-post-template-js",
    "path": "/pypspark-bolierplate-for-etl-project/",
    "result": {"data":{"post":{"id":"57592df0-4a2a-5646-b635-241fac7c5a8a","html":"<p>Untuk para data engineer, siapa yang tidak mengenal library <a href=\"https://spark.apache.org/\">Apache Spark</a> ??? sebuah mesin analitikal untuk pemrosesan dataset yang besar. Umumnya pemrosesan data yang dilakukan berkaitan dengan mengambil dari berbagai sumber data dan melakukan proses aggregasi atau penggabungan data sehingga menghasilkan suatu informasi baik berupa report, ataupun sebuah rekomendasi jika didalamnya terdapat proses pembelajaran oleh algoritma machine learning. Dari kompleksitas diatas, ada istilah umum yang sering digunakan, yaitu <a href=\"https://en.wikipedia.org/wiki/Extract,_transform,_load\">ETL (Extract, Transform, Load)</a>. Untuk itu, pada artikel ini, saya akan menjelaskan mengenai cara menggunakan spark dengan interaksi high-level api menggunakan pyspark yang berbasis Python.</p>\n<p>Dalam artikel ini, kita akan membuat sebuah kerangka kerja atau bolierplate pyspark sebagai pendekatan untuk melakukan proses ETL. Yang akan kita bahas meliputi</p>\n<ul>\n<li>Instalasi dan management virtual environtment python</li>\n<li>Penyusunan struktur project pyspark</li>\n<li>Menangani struktur dependency dan paket untuk flow pyspark</li>\n</ul>\n<h2>Persiapan Instalasi Paket</h2>\n<p>Untuk memulai project python, saya pribadi lebih sering menggunakan virtual environtment agar dependensi projeknya tidak tercampur aduk antara satu projek dengan projek lainnya. Seringnya saya menggunakan pipenv sebagai paket manager projek. Untuk referensinya dapat dibaca pada tautan berikut <a href=\"https://ypraw.github.io/management-paket-dan-virtual-environtment-menggunakan-pipenv/\">Pipenv</a>.\nAtau anda dapat pula menggunakan venv.</p>\n<p>langkah pertama, pastikan spark telah terinstall pada perangkat anda, jika belum anda dapat melakukan instalasi melalui tautan berikut <a href=\"https://spark.apache.org/downloads.html\">spark</a></p>\n<p>Langkah berikutnya yaitu memasang pyspark dengan perintah :</p>\n<ul>\n<li>Jika menggunakan pipenv</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">pipenv <span class=\"token function\">install</span> pyspark</code></pre></div>\n<ul>\n<li>Jika menggunakan pip</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">pip <span class=\"token function\">install</span> pyspark</code></pre></div>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Untuk para data engineer, siapa yang tidak mengenal library "},{"type":"element","tagName":"a","properties":{"href":"https://spark.apache.org/"},"children":[{"type":"text","value":"Apache Spark"}]},{"type":"text","value":" ??? sebuah mesin analitikal untuk pemrosesan dataset yang besar. Umumnya pemrosesan data yang dilakukan berkaitan dengan mengambil dari berbagai sumber data dan melakukan proses aggregasi atau penggabungan data sehingga menghasilkan suatu informasi baik berupa report, ataupun sebuah rekomendasi jika didalamnya terdapat proses pembelajaran oleh algoritma machine learning. Dari kompleksitas diatas, ada istilah umum yang sering digunakan, yaitu "},{"type":"element","tagName":"a","properties":{"href":"https://en.wikipedia.org/wiki/Extract,_transform,_load"},"children":[{"type":"text","value":"ETL (Extract, Transform, Load)"}]},{"type":"text","value":". Untuk itu, pada artikel ini, saya akan menjelaskan mengenai cara menggunakan spark dengan interaksi high-level api menggunakan pyspark yang berbasis Python."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Dalam artikel ini, kita akan membuat sebuah kerangka kerja atau bolierplate pyspark sebagai pendekatan untuk melakukan proses ETL. Yang akan kita bahas meliputi"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Instalasi dan management virtual environtment python"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Penyusunan struktur project pyspark"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Menangani struktur dependency dan paket untuk flow pyspark"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Persiapan Instalasi Paket"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Untuk memulai project python, saya pribadi lebih sering menggunakan virtual environtment agar dependensi projeknya tidak tercampur aduk antara satu projek dengan projek lainnya. Seringnya saya menggunakan pipenv sebagai paket manager projek. Untuk referensinya dapat dibaca pada tautan berikut "},{"type":"element","tagName":"a","properties":{"href":"https://ypraw.github.io/management-paket-dan-virtual-environtment-menggunakan-pipenv/"},"children":[{"type":"text","value":"Pipenv"}]},{"type":"text","value":".\nAtau anda dapat pula menggunakan venv."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"langkah pertama, pastikan spark telah terinstall pada perangkat anda, jika belum anda dapat melakukan instalasi melalui tautan berikut "},{"type":"element","tagName":"a","properties":{"href":"https://spark.apache.org/downloads.html"},"children":[{"type":"text","value":"spark"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Langkah berikutnya yaitu memasang pyspark dengan perintah :"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Jika menggunakan pipenv"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"bash"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-bash"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-bash"]},"children":[{"type":"text","value":"pipenv "},{"type":"element","tagName":"span","properties":{"className":["token","function"]},"children":[{"type":"text","value":"install"}]},{"type":"text","value":" pyspark"}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Jika menggunakan pip"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"bash"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-bash"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-bash"]},"children":[{"type":"text","value":"pip "},{"type":"element","tagName":"span","properties":{"className":["token","function"]},"children":[{"type":"text","value":"install"}]},{"type":"text","value":" pyspark"}]}]}]}],"data":{"quirksMode":false}},"excerpt":"Untuk para data engineer, siapa yang tidak mengenal library Apache Spark ??? sebuah mesin analitikal untuk pemrosesan dataset yang besar. Umumnya pemrosesan data yang dilakukan berkaitan dengan mengambil dari berbagai sumber data dan melakukan proses aggregasi atau penggabungan…","fields":{"slug":"/pypspark-bolierplate-for-etl-project/","prefix":"draft/2021-09-27"},"frontmatter":{"title":"Pypspark Bolierplate for ETL Project","author":"yunindyo prabowo","category":["python","data engineer","etl","elt","pyspark"]}},"authornote":{"id":"e85cae6e-b60f-5a2c-bea1-29a661f94eb3","html":"<p>Programmer from Indonesia, Dark World enthusiast especially coffee and terminals,\nhave a dream to be a pythonist</p>"}},"pageContext":{"slug":"/pypspark-bolierplate-for-etl-project/","prev":{"id":"0aceb334-2951-5647-b87b-aa459206a445","excerpt":"Siapa bilang bahwa rumus pythagoras yang terkenal itu cuma konsep matematika yang diajarin dan ngga berguna didunia nyata, atau bahkan cuma sekedar masuk kuping kanan, muter-muter diotak sebentar, terus keluar lagi dari kuping kiri ??? Atau jangan-jangan malah kalian lupa sama sekali rumusnya…","fields":{"slug":"/k-nearest-neighbor-algorithm-on-python/","prefix":"draft/2021-06-29","source":"posts"},"frontmatter":{"title":"K-Nearest Neighbor Algorithm on Python","category":["python","data scientist","machine learning","supervised algorithm","knn","nearest neighbors","k-nn"]}},"source":"posts"}},
    "staticQueryHashes": ["1722218574","2797806559","2909820253"]}